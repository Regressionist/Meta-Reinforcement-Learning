{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "from atari_wrappers import wrap_dqn\n",
    "from Agent import Agent\n",
    "\n",
    "from IPython import display\n",
    "plt.ion()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Use GPU: {}'.format(use_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(skip=True,episodic=True)\n",
    "#agent.load_model('/scratch/ab8084/atari/saved/final_model_breakout.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training at: Tue May  7 15:14:47 2019\n",
      "Populating Replay Buffer\n",
      "\n",
      "\n",
      "Replay Buffer populated with 50000 transitions, starting training...\n",
      "\n",
      "\n",
      "synchronizing target network...\n",
      "global step: 42  | episode: 1  | episode_length: 42  | episode reward: 3.0\n",
      "global step: 2739  | episode: 252  | episode_length: 46  | episode reward: 4.0\n",
      "synchronizing target network...\n",
      "global step: 10697  | episode: 1000  | mean episode_length: 10.697  | mean episode reward: 0.34\n",
      "synchronizing target network...\n",
      "global step: 21933  | episode: 2000  | mean episode_length: 11.236  | mean episode reward: 0.344\n",
      "synchronizing target network...\n",
      "global step: 33304  | episode: 3000  | mean episode_length: 11.371  | mean episode reward: 0.385\n",
      "global step: 34814  | episode: 3115  | episode_length: 52  | episode reward: 5.0\n",
      "synchronizing target network...\n",
      "global step: 46952  | episode: 4000  | mean episode_length: 13.648  | mean episode reward: 0.453\n",
      "synchronizing target network...\n",
      "global step: 59632  | episode: 4971  | episode_length: 53  | episode reward: 6.0\n",
      "global step: 59989  | episode: 5000  | mean episode_length: 13.037  | mean episode reward: 0.613\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 75060  | episode: 6000  | mean episode_length: 15.071  | mean episode reward: 0.859\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 95599  | episode: 7000  | mean episode_length: 20.539  | mean episode reward: 1.311\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 113294  | episode: 7315  | episode_length: 55  | episode reward: 7.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 133811  | episode: 7675  | episode_length: 156  | episode reward: 8.0\n",
      "synchronizing target network...\n",
      "global step: 144378  | episode: 7873  | episode_length: 128  | episode reward: 9.0\n",
      "synchronizing target network...\n",
      "global step: 151196  | episode: 8000  | mean episode_length: 55.597  | mean episode reward: 2.423\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 177357  | episode: 8567  | episode_length: 202  | episode reward: 10.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 193769  | episode: 9000  | mean episode_length: 42.573  | mean episode reward: 2.891\n",
      "global step: 198405  | episode: 9146  | episode_length: 113  | episode reward: 12.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 241433  | episode: 10000  | mean episode_length: 47.664  | mean episode reward: 3.345\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 290948  | episode: 10875  | episode_length: 117  | episode reward: 13.0\n",
      "global step: 295895  | episode: 11000  | mean episode_length: 54.462  | mean episode reward: 3.714\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 333455  | episode: 11786  | episode_length: 353  | episode reward: 14.0\n",
      "synchronizing target network...\n",
      "global step: 345877  | episode: 12000  | mean episode_length: 49.982  | mean episode reward: 3.988\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 408197  | episode: 13000  | mean episode_length: 62.32  | mean episode reward: 4.214\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 425476  | episode: 13336  | episode_length: 143  | episode reward: 17.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 459550  | episode: 14000  | mean episode_length: 51.353  | mean episode reward: 4.481\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 517605  | episode: 15000  | mean episode_length: 58.055  | mean episode reward: 4.446\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 595560  | episode: 16000  | mean episode_length: 77.955  | mean episode reward: 4.66\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 617153  | episode: 16359  | episode_length: 240  | episode reward: 20.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 657918  | episode: 17000  | mean episode_length: 62.358  | mean episode reward: 4.932\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 728522  | episode: 18000  | mean episode_length: 70.604  | mean episode reward: 5.072\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 801373  | episode: 19000  | mean episode_length: 72.851  | mean episode reward: 4.925\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 828070  | episode: 19349  | episode_length: 188  | episode reward: 21.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 854638  | episode: 19661  | episode_length: 172  | episode reward: 22.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 880303  | episode: 20000  | mean episode_length: 78.93  | mean episode reward: 5.001\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 956248  | episode: 21000  | mean episode_length: 75.945  | mean episode reward: 5.023\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1034371  | episode: 22000  | mean episode_length: 78.123  | mean episode reward: 5.116\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1108782  | episode: 23000  | mean episode_length: 74.411  | mean episode reward: 5.014\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1199567  | episode: 24000  | mean episode_length: 90.785  | mean episode reward: 4.931\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1280155  | episode: 25000  | mean episode_length: 80.588  | mean episode reward: 5.164\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synchronizing target network...\n",
      "global step: 1367998  | episode: 26000  | mean episode_length: 87.843  | mean episode reward: 5.128\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1424900  | episode: 26779  | episode_length: 186  | episode reward: 23.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1441846  | episode: 27000  | mean episode_length: 73.848  | mean episode reward: 5.287\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1476350  | episode: 27436  | episode_length: 222  | episode reward: 24.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1516518  | episode: 28000  | mean episode_length: 74.672  | mean episode reward: 5.328\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1584431  | episode: 29000  | mean episode_length: 67.913  | mean episode reward: 5.194\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1657044  | episode: 30000  | mean episode_length: 72.613  | mean episode reward: 5.5\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1723930  | episode: 31000  | mean episode_length: 66.886  | mean episode reward: 5.359\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1791408  | episode: 32000  | mean episode_length: 67.478  | mean episode reward: 5.304\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1859394  | episode: 33000  | mean episode_length: 67.986  | mean episode reward: 5.486\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 1937723  | episode: 34000  | mean episode_length: 78.329  | mean episode reward: 5.456\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2015337  | episode: 35000  | mean episode_length: 77.614  | mean episode reward: 5.619\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2095035  | episode: 36000  | mean episode_length: 79.698  | mean episode reward: 5.526\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2172687  | episode: 37000  | mean episode_length: 77.652  | mean episode reward: 5.694\n",
      "synchronizing target network...\n",
      "global step: 2188688  | episode: 37192  | episode_length: 200  | episode reward: 25.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2248862  | episode: 38000  | mean episode_length: 76.175  | mean episode reward: 5.745\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2304468  | episode: 38676  | episode_length: 199  | episode reward: 26.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2332982  | episode: 39000  | mean episode_length: 84.12  | mean episode reward: 5.674\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2416402  | episode: 40000  | mean episode_length: 83.42  | mean episode reward: 5.643\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2437021  | episode: 40256  | episode_length: 95  | episode reward: 27.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2492244  | episode: 41000  | mean episode_length: 75.842  | mean episode reward: 5.769\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2564358  | episode: 42000  | mean episode_length: 72.114  | mean episode reward: 5.728\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2669797  | episode: 43000  | mean episode_length: 105.439  | mean episode reward: 5.517\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2748404  | episode: 44000  | mean episode_length: 78.607  | mean episode reward: 5.751\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2830585  | episode: 45000  | mean episode_length: 82.181  | mean episode reward: 5.509\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2907069  | episode: 46000  | mean episode_length: 76.484  | mean episode reward: 5.671\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 2984262  | episode: 47000  | mean episode_length: 77.193  | mean episode reward: 5.589\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3063135  | episode: 48000  | mean episode_length: 78.873  | mean episode reward: 5.773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3115964  | episode: 48761  | episode_length: 225  | episode reward: 29.0\n",
      "synchronizing target network...\n",
      "global step: 3127171  | episode: 48915  | episode_length: 99  | episode reward: 31.0\n",
      "synchronizing target network...\n",
      "global step: 3132302  | episode: 49000  | mean episode_length: 69.167  | mean episode reward: 5.567\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3210307  | episode: 50000  | mean episode_length: 78.005  | mean episode reward: 5.699\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3280745  | episode: 51000  | mean episode_length: 70.438  | mean episode reward: 5.642\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3355496  | episode: 52000  | mean episode_length: 74.751  | mean episode reward: 5.732\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3434625  | episode: 53000  | mean episode_length: 79.129  | mean episode reward: 5.633\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3499928  | episode: 54000  | mean episode_length: 65.303  | mean episode reward: 5.834\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3585319  | episode: 55000  | mean episode_length: 85.391  | mean episode reward: 5.888\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3655884  | episode: 56000  | mean episode_length: 70.565  | mean episode reward: 5.929\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3750118  | episode: 57000  | mean episode_length: 94.234  | mean episode reward: 5.963\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3827208  | episode: 58000  | mean episode_length: 77.09  | mean episode reward: 5.748\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3897373  | episode: 59000  | mean episode_length: 70.165  | mean episode reward: 5.897\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 3974604  | episode: 60000  | mean episode_length: 77.231  | mean episode reward: 5.994\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4052857  | episode: 61000  | mean episode_length: 78.253  | mean episode reward: 6.042\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4113377  | episode: 61804  | episode_length: 261  | episode reward: 36.0\n",
      "synchronizing target network...\n",
      "global step: 4128288  | episode: 62000  | mean episode_length: 75.431  | mean episode reward: 5.919\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4208310  | episode: 63000  | mean episode_length: 80.022  | mean episode reward: 5.85\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4282913  | episode: 64000  | mean episode_length: 74.603  | mean episode reward: 5.912\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4359529  | episode: 65000  | mean episode_length: 76.616  | mean episode reward: 5.835\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4444539  | episode: 66000  | mean episode_length: 85.01  | mean episode reward: 5.93\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4522782  | episode: 67000  | mean episode_length: 78.243  | mean episode reward: 5.999\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4596665  | episode: 68000  | mean episode_length: 73.883  | mean episode reward: 5.897\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4678526  | episode: 69000  | mean episode_length: 81.861  | mean episode reward: 5.848\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4758346  | episode: 70000  | mean episode_length: 79.82  | mean episode reward: 5.894\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4840888  | episode: 71000  | mean episode_length: 82.542  | mean episode reward: 5.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4928801  | episode: 72000  | mean episode_length: 87.913  | mean episode reward: 5.958\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 4995974  | episode: 72853  | episode_length: 280  | episode reward: 39.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5010865  | episode: 73000  | mean episode_length: 82.064  | mean episode reward: 5.888\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5083994  | episode: 74000  | mean episode_length: 73.129  | mean episode reward: 6.132\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5167942  | episode: 75000  | mean episode_length: 83.948  | mean episode reward: 5.9\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5243122  | episode: 76000  | mean episode_length: 75.18  | mean episode reward: 6.071\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5325936  | episode: 77000  | mean episode_length: 82.814  | mean episode reward: 5.943\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5405914  | episode: 78000  | mean episode_length: 79.978  | mean episode reward: 5.999\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5485455  | episode: 79000  | mean episode_length: 79.541  | mean episode reward: 6.187\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5553345  | episode: 80000  | mean episode_length: 67.89  | mean episode reward: 6.027\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5625542  | episode: 81000  | mean episode_length: 72.197  | mean episode reward: 5.811\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5694472  | episode: 82000  | mean episode_length: 68.93  | mean episode reward: 6.027\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5767988  | episode: 83000  | mean episode_length: 73.516  | mean episode reward: 5.788\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5850419  | episode: 84000  | mean episode_length: 82.431  | mean episode reward: 6.038\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 5934842  | episode: 85000  | mean episode_length: 84.423  | mean episode reward: 5.976\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6006234  | episode: 86000  | mean episode_length: 71.392  | mean episode reward: 5.907\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6084021  | episode: 87000  | mean episode_length: 77.787  | mean episode reward: 5.901\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6164607  | episode: 88000  | mean episode_length: 80.586  | mean episode reward: 6.124\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6242413  | episode: 89000  | mean episode_length: 77.806  | mean episode reward: 6.009\n",
      "global step: 6246202  | episode: 89055  | episode_length: 105  | episode reward: 46.0\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6313979  | episode: 90000  | mean episode_length: 71.566  | mean episode reward: 6.149\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6393738  | episode: 91000  | mean episode_length: 79.759  | mean episode reward: 5.96\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6470903  | episode: 92000  | mean episode_length: 77.165  | mean episode reward: 6.028\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6549310  | episode: 93000  | mean episode_length: 78.407  | mean episode reward: 5.981\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6637734  | episode: 94000  | mean episode_length: 88.424  | mean episode reward: 6.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6720792  | episode: 95000  | mean episode_length: 83.058  | mean episode reward: 6.127\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6810875  | episode: 96000  | mean episode_length: 90.083  | mean episode reward: 5.998\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6884263  | episode: 97000  | mean episode_length: 73.388  | mean episode reward: 5.966\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 6956330  | episode: 98000  | mean episode_length: 72.067  | mean episode reward: 6.102\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7027629  | episode: 99000  | mean episode_length: 71.299  | mean episode reward: 5.682\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7099303  | episode: 100000  | mean episode_length: 71.674  | mean episode reward: 6.053\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7167759  | episode: 101000  | mean episode_length: 68.456  | mean episode reward: 6.004\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7241131  | episode: 102000  | mean episode_length: 73.372  | mean episode reward: 5.804\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7302571  | episode: 103000  | mean episode_length: 61.44  | mean episode reward: 5.48\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7374013  | episode: 104000  | mean episode_length: 71.442  | mean episode reward: 5.779\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7449733  | episode: 105000  | mean episode_length: 75.72  | mean episode reward: 6.15\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7526772  | episode: 106000  | mean episode_length: 77.039  | mean episode reward: 6.042\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7601199  | episode: 107000  | mean episode_length: 74.427  | mean episode reward: 6.004\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7676094  | episode: 108000  | mean episode_length: 74.895  | mean episode reward: 5.963\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7746045  | episode: 109000  | mean episode_length: 69.951  | mean episode reward: 5.872\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7823011  | episode: 110000  | mean episode_length: 76.966  | mean episode reward: 6.245\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7892515  | episode: 111000  | mean episode_length: 69.504  | mean episode reward: 6.099\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 7964381  | episode: 112000  | mean episode_length: 71.866  | mean episode reward: 6.183\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8042366  | episode: 113000  | mean episode_length: 77.985  | mean episode reward: 6.265\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8122428  | episode: 114000  | mean episode_length: 80.062  | mean episode reward: 6.26\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8197162  | episode: 115000  | mean episode_length: 74.734  | mean episode reward: 5.894\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8271032  | episode: 116000  | mean episode_length: 73.87  | mean episode reward: 6.01\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8337525  | episode: 117000  | mean episode_length: 66.493  | mean episode reward: 5.697\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8423202  | episode: 118000  | mean episode_length: 85.677  | mean episode reward: 5.876\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8494007  | episode: 119000  | mean episode_length: 70.805  | mean episode reward: 5.936\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8560540  | episode: 120000  | mean episode_length: 66.533  | mean episode reward: 5.971\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8631715  | episode: 121000  | mean episode_length: 71.175  | mean episode reward: 6.271\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8696702  | episode: 122000  | mean episode_length: 64.987  | mean episode reward: 6.018\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8782555  | episode: 123000  | mean episode_length: 85.853  | mean episode reward: 6.341\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8865239  | episode: 124000  | mean episode_length: 82.684  | mean episode reward: 6.352\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 8944933  | episode: 125000  | mean episode_length: 79.694  | mean episode reward: 5.956\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 9027384  | episode: 126000  | mean episode_length: 82.451  | mean episode reward: 5.95\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 9096780  | episode: 127000  | mean episode_length: 69.396  | mean episode reward: 6.021\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "global step: 9169086  | episode: 128000  | mean episode_length: 72.306  | mean episode reward: 6.036\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n",
      "synchronizing target network...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-785532c9f56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mepsilon_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mepsilon_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             sync_target_net_freq=10000)\n\u001b[0m",
      "\u001b[0;32m~/Git projects/Atari/Model/Breakout/skipTrue/Agent.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, replay_buffer_fill_len, batch_size, episodes, stop_reward, max_epsilon_steps, epsilon_start, epsilon_final, sync_target_net_freq)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epsilon_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git projects/Atari/Model/Breakout/skipTrue/Agent.py\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state, epsilon)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_q_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git projects/Atari/Model/Breakout/skipTrue/Agent.py\u001b[0m in \u001b[0;36mpredict_q_values\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     66\u001b[0m         '''\n\u001b[1;32m     67\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mactions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git projects/Atari/Model/Breakout/skipTrue/DQN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0msshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         '''\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(replay_buffer_fill_len=50000, \n",
    "            batch_size=32, \n",
    "            episodes=10**6,\n",
    "            stop_reward=1900,\n",
    "            max_epsilon_steps=100000,\n",
    "            epsilon_start=1,\n",
    "            epsilon_final=0.05,\n",
    "            sync_target_net_freq=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(1):\n",
    "        done=False\n",
    "        agent=Agent(skip=False,episodic=True)\n",
    "        #agent.load_model('/scratch/ab8084/atari/saved/final_model_boxing.pth')\n",
    "        #agent.env = gym.wrappers.Monitor(agent.env, \"recording\")\n",
    "        plt.figure(figsize=(10,8))\n",
    "        state=agent.env.reset()\n",
    "        #print(state.shape)\n",
    "        plt.imshow(agent.env.render(mode='rgb_array'))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        while not done:\n",
    "            action = agent.select_action(state, 0)\n",
    "            state, reward, done, _ = agent.env.step(action)\n",
    "            display.clear_output(wait=True)\n",
    "            plt.figure(figsize=(10,8))\n",
    "            plt.imshow(agent.env.render(mode='rgb_array'))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            #time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b47aadd0198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(state)[3],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
